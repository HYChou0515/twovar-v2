This is the experimental code for the "Two-variable Block Dual Coordinate 
Descent Methods for Large-scale Linear Support Vector Machines"

This code will generate the experimental results in paper.

Experiment Data
================
Download the datasets from LIBSVM datasets
	http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html

`train' Usage
================

Usage: train [options] training_set_file [model_file]
options:
-s type : set type of solver (default 1)
  for multi-class classification
	 1 -- L2-loss support vector classification (1-CD-perm-shrink)
	 3 -- L1-loss support vector classification (1-CD-perm-shrink)
	 
	 21 -- L1-loss support vector classification (1-CD-perm)
	 22 -- L1-loss support vector classification (1-CD-random)
	 23 -- L1-loss support vector classification (1-CD-random-shrink)
	 24 -- L2-loss support vector classification (1-CD-perm)
	 25 -- L2-loss support vector classification (1-CD-random)
	 26 -- L2-loss support vector classification (1-CD-random-shrink)

	 31 -- L1-loss support vector classification (2-CD-perm)
	 32 -- L1-loss support vector classification (2-CD-random)
	 33 -- L1-loss support vector classification (2-CD-random-shrink)
	 34 -- L2-loss support vector classification (2-CD-perm)
	 35 -- L2-loss support vector classification (2-CD-random)
	 36 -- L2-loss support vector classification (2-CD-random-shrink)
	 37 -- L1-loss support vector classification (2-CD-semiperm)
	 38 -- L2-loss support vector classification (2-CD-semiperm)

	 41 -- L1-loss standard support vector classification (2-CD-bias)
	 42 -- L2-loss standard support vector classification (2-CD-bias)


-c cost : set the parameter C (default 1)
-e epsilon : set tolerance of termination criterion
		Dual maximal violation <= eps; similar to libsvm (default 0.1)


Formulations:

For L2-regularized L2-loss SVC dual (-s 1, 24, 25, 26, 34, 35, 36, 38), we solve

min_alpha  0.5(alpha^T (Q + I/2/C) alpha) - e^T alpha
    s.t.   0 <= alpha_i,

For L2-regularized L1-loss SVC dual (-s 3, 21, 22, 23, 31, 32, 33, 37), we solve

min_alpha  0.5(alpha^T Q alpha) - e^T alpha
    s.t.   0 <= alpha_i <= C,

For L2-regularized L2-loss standar SVC dual (-s 42), we solve

min_alpha  0.5(alpha^T (Q + I/2/C) alpha) - e^T alpha
    s.t.   0 <= alpha_i,
           y^T alpha = 0,

For L2-regularized L1-loss standard SVC dual (-s 41), we solve

min_alpha  0.5(alpha^T Q alpha) - e^T alpha
    s.t.   0 <= alpha_i <= C,
           y^T alpha = 0,

where

Q is a matrix with Q_ij = y_i y_j x_i^T x_j.


How to Add New Solver Type (-s)
===============================
1. linear.h
	append NEWTYPE to solver_type enum with a valid code
	example:
		code=abcde
		a: big category
		bc: algo
		d: loss 1 or 2
		e: 1000 iter or shrink
2. train.c
	append NEWTYPE info to exit_with_help()
3. linear.cpp
	a) Solver::Solver
		i) 	determine category
		ii) SAVE_NAME	
	b) (big) update function (e.g. onetwo_nobias_update)
		i)
			NEWTYPE is default L2
			if NEWTYPE is L1, change diag and upper_bound 	
		ii)
			switch solver_type and run the (detailed) update function
	c) train_one()
		assign (big) update function
	d) Solver_type_table
		SAVE_NAME to the solver type table
	e) check_parameter()
		exit if solver_type is not equal to NEWTYPE or other
4. script/liblrconf.py
	a) append NEWTYPE code to runs = {}
	b) modify semigd_prefix = []
